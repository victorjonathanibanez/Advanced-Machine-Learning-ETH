{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: PREDICT THE AGE OF A BRAIN FROM MRI FEATURES\n",
    "\n",
    "This task is primarily concerned with regression. However, we have perturbed the original MRI features in several ways.\n",
    "\n",
    "You will have to perform the following preprocessing steps:\n",
    "\n",
    "- outlier detection\n",
    "- feature selection\n",
    "- imputation of missing values\n",
    "\n",
    "You are required to document each of the three steps in the description that you will submit with your project. Besides the data processing steps, you have to provide a succint description of the regression model you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "\n",
    "X_train['y'] = y_train['y']\n",
    "mri = X_train\n",
    "mri = mri.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mri.loc[:, mri.columns != 'y']\n",
    "y_train = mri['y']\n",
    "X_test = X_test.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 832)\n",
      "(1212,)\n",
      "(776, 832)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle image list\n",
    "obs = mri.index.tolist()\n",
    "random.seed(17)\n",
    "random.shuffle(obs)\n",
    "\n",
    "# set percentages of training set size\n",
    "train_p = 99 # val_p = 100-train_p\n",
    "\n",
    "# split into training and testing list\n",
    "train_l = obs[0:math.floor(len(obs)/100*train_p)]\n",
    "val_l = obs[len(train_l):]\n",
    "\n",
    "training = mri.loc[train_l]\n",
    "validation = mri.loc[val_l]\n",
    "\n",
    "# detecting outliers with IQR (interquartile range)\n",
    "Q1 = training.loc[:, training.columns != 'y'].quantile(0.25)\n",
    "Q3 = training.loc[:, training.columns != 'y'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "training_no = training[~((training < (Q1 - 100 * IQR)) |(training > (Q3 + 100 * IQR))).any(axis=1)]\n",
    "\n",
    "X_train = training_no.loc[:, training.columns != 'y']\n",
    "y_train = training_no['y']\n",
    "X_val = validation.drop(columns='y')\n",
    "y_val = validation['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers removed: 0\n",
      "Remaining samples: 1199\n",
      "Validation samples: 13\n"
     ]
    }
   ],
   "source": [
    "print('Outliers removed: {}'.format(training.shape[0] - training_no.shape[0]))\n",
    "print('Remaining samples: {}'.format(X_train.shape[0]))\n",
    "print('Validation samples: {}'.format(X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple impute data\n",
    "def simple_impute(X_train, X_val, method):\n",
    "    col_names = X_train.columns.tolist()\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=method)\n",
    "    X_train_imp = imputer.fit_transform(X_train)\n",
    "    X_val_imp = imputer.transform(X_val)\n",
    "    \n",
    "    return X_train_imp, X_val_imp, imputer\n",
    "\n",
    "# knn impute data\n",
    "def knn_impute(X_train, X_val, k):\n",
    "    col_names = X_train.columns.tolist()\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    X_train_imp = imputer.fit_transform(X_train)\n",
    "    X_val_imp = imputer.transform(X_val)\n",
    "    \n",
    "    return X_train_imp, X_val_imp, imputer\n",
    "\n",
    "# iterative imputer\n",
    "def iter_impute(X_train, X_val):\n",
    "    col_names = X_train.columns.tolist()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    imputer = IterativeImputer(max_iter=10, verbose=1, n_nearest_features=20)\n",
    "    X_train_imp = imputer.fit_transform(X_train)\n",
    "    X_val_imp = imputer.transform(X_val)\n",
    "    print('{} seconds'.format(round(time.time() - start_time)))\n",
    "    \n",
    "    return X_train_imp, X_val_imp, imputer\n",
    "\n",
    "def check_for_nan(np_array):\n",
    "    np_array_sum = np.sum(np_array)\n",
    "    array_has_nan = np.isnan(np_array_sum)\n",
    "    print(array_has_nan)\n",
    "    \n",
    "def check_for_finite(np_array):\n",
    "    output = np.all(np.isfinite(np_array))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp, X_val_imp, imputer = simple_impute(X_train, X_test, 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "check_for_nan(X_train_imp)\n",
    "check_for_nan(X_val_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection. \n",
    "# method = f_regression for correlation; mutual_info_regression for mutual information\n",
    "def select_features(X_train, y_train, X_test, method, n_features): #Â \n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=method, k=n_features)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_feature_elimination(X_train, y_train, X_val, estim):\n",
    "    rfecv = RFECV(estimator=estim, step=1, cv=KFold(2), n_jobs=-1)\n",
    "    rfecv = rfecv.fit(X_train, y_train)\n",
    "    X_train_selected = rfecv.transform(X_train)\n",
    "    X_val_selected = rfecv.transform(X_val)\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "    return(X_train_selected, X_val_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lau/opt/anaconda3/envs/face/lib/python3.6/site-packages/sklearn/feature_selection/_univariate_selection.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/lau/opt/anaconda3/envs/face/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1932: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    }
   ],
   "source": [
    "X_train_cor, X_val_cor, cor = select_features(X_train_imp, y_train, X_val_imp, f_regression, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 100)\n",
      "(776, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cor.shape)\n",
    "print(X_val_cor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 59\n",
      "1070 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "X_train_sel, X_val_sel = recursive_feature_elimination(X_train_cor, y_train, X_val_cor,\n",
    "                                                      ExtraTreesRegressor(n_estimators=1470, n_jobs=-1))\n",
    "print('{} seconds'.format(round(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 59)\n",
      "(776, 59)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sel.shape)\n",
    "print(X_val_sel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean=0, var=1\n",
    "def standardize(X_train, X_val):\n",
    "    transformer = preprocessing.StandardScaler()\n",
    "    X_train_trans = transformer.fit_transform(X_train)\n",
    "    X_val_trans = transformer.transform(X_val)\n",
    "    return X_train_trans, X_val_trans, transformer\n",
    "\n",
    "# scale to [min, max]\n",
    "def minmax(X_train, X_val, range_tuple): # e.g. (-1, 1)\n",
    "    transformer = preprocessing.MinMaxScaler(feature_range=range_tuple)\n",
    "    X_train_trans = transformer.fit_transform(X_train)\n",
    "    X_val_trans = transformer.transform(X_val)\n",
    "    return X_train_trans, X_val_trans, transformer\n",
    "\n",
    "# powertransform\n",
    "def powertransform(X_train, X_val):\n",
    "    transformer = PowerTransformer()\n",
    "    X_train_trans = transformer.fit_transform(X_train)\n",
    "    X_val_trans = transformer.transform(X_val)\n",
    "    return X_train_trans, X_val_trans, transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "X_train_stand, X_test_stand, standard_scaler = standardize(X_train_sel, X_val_sel)\n",
    "X_train_minmax, X_test_minmax, minmax_scaler = minmax(X_train_sel, X_val_sel, (-1, 1))\n",
    "X_train_minmax01, X_test_minmax01, minmax_scaler01 = minmax(X_train_sel, X_val_sel, (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Cross Validated Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators' : n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ExtraTreesRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = est, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, n_jobs = -1)\n",
    "rf_random.fit(X_train_sel, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning with Cross Validated Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "regf_grid = GridSearchCV(MLPRegressor(max_iter=10000, activation='tanh', solver='sgd'), parameter_grid, n_jobs=-1)\n",
    "regf_grid.fit(X_train_minmax01, y_train)\n",
    "\n",
    "print('{} seconds'.format(round(time.time() - start_time)))\n",
    "print()\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(regf_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "means = regf_grid.cv_results_['mean_test_score']\n",
    "stds = regf_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, regf_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regf = ExtraTreesRegressor(n_estimators=1740, max_depth=53)\n",
    "regf_cv = cross_val_score(regf, X_train_minmax, y_train, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r2: %0.4f (+/- %0.2f)\" % (regf_cv.mean(), regf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees regression\n",
    "extra_tree = ExtraTreesRegressor(random_state=0, n_estimators=1740, max_depth=60, n_jobs=-1)\n",
    "extra_tree.fit(X_train_minmax, y_train)\n",
    "extra_pred = extra_tree.predict(X_test_minmax)\n",
    "\n",
    "print(r2_score(y_val, extra_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = np.array(range(len(X_test_minmax)))\n",
    "df = pd.DataFrame({'id': ID,\n",
    "                    'y': extra_pred})\n",
    "df.to_csv('/Users/lau/Desktop/prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| $R^{2}$ scores | |\n",
    ":- | :-\n",
    "hard baseline | 0.65\n",
    "public test set | 0.6568\n",
    "private test set | 0.6042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
